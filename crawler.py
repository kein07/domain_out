import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import time
import re

# --- è¨­å®šé …ç›® ---
# ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’é–‹å§‹ã™ã‚‹ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®ãƒªã‚¹ãƒˆï¼ˆä»Šå›ã¯æœ€åˆã®1ã¤ã ã‘ä½¿ã„ã¾ã™ï¼‰
INPUT_FILE = "domains.txt" 
# è¦‹ã¤ã‹ã£ãŸco.jpãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
OUTPUT_FILE = "found_cojp_links.txt"
# --- è¨­å®šé …ç›®ã“ã“ã¾ã§ ---

# è¨ªå•æ¸ˆã¿ã®URLã‚’è¨˜éŒ²ã™ã‚‹ã‚»ãƒƒãƒˆï¼ˆé‡è¤‡ã‚¢ã‚¯ã‚»ã‚¹ã‚’é˜²ããŸã‚ï¼‰
visited_urls = set()
# è¦‹ã¤ã‹ã£ãŸco.jpãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’è¨˜éŒ²ã™ã‚‹ã‚»ãƒƒãƒˆï¼ˆé‡è¤‡ã‚’ãªãã™ãŸã‚ï¼‰
found_cojp_domains = set()

def crawl(url, base_domain):
    """
    å†å¸°çš„ã«ãƒšãƒ¼ã‚¸ã‚’ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã€co.jpãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã™é–¢æ•°
    """
    # æ—¢ã«è¨ªå•æ¸ˆã¿ã®URLã¯ã‚¹ã‚­ãƒƒãƒ—
    if url in visited_urls:
        return
    
    print(f"ğŸ” ã‚¯ãƒ­ãƒ¼ãƒ«ä¸­: {url}")
    visited_urls.add(url)

    try:
        # ãƒšãƒ¼ã‚¸ã‚’å–å¾—
        response = requests.get(url, timeout=10)
        response.raise_for_status() # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿ
        
        # æ–‡å­—åŒ–ã‘å¯¾ç­–
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")

        # ãƒšãƒ¼ã‚¸å†…ã®å…¨ã¦ã®<a>ã‚¿ã‚°ï¼ˆãƒªãƒ³ã‚¯ï¼‰ã‚’æ¢ã™
        for link in soup.find_all('a', href=True):
            href = link['href']
            
            # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾URLã«å¤‰æ› (ä¾‹: /about.html -> http://example.com/about.html )
            full_url = urljoin(url, href)
            
            # URLã®è§£æ
            parsed_url = urlparse(full_url)
            domain = parsed_url.netloc

            # 1. ãƒªãƒ³ã‚¯å…ˆãŒco.jpãƒ‰ãƒ¡ã‚¤ãƒ³ã®å ´åˆ
            if domain.endswith('.co.jp'):
                if domain not in found_cojp_domains:
                    print(f"âœ¨ co.jpãƒ‰ãƒ¡ã‚¤ãƒ³ç™ºè¦‹: {domain}")
                    found_cojp_domains.add(domain)

            # 2. ãƒªãƒ³ã‚¯å…ˆãŒåŒã˜ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆå†…ï¼ˆbase_domainï¼‰ã®å ´åˆã€ã•ã‚‰ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’ç¶šã‘ã‚‹
            if domain == base_domain:
                # URLã®#ä»¥é™ï¼ˆãƒšãƒ¼ã‚¸å†…ãƒªãƒ³ã‚¯ï¼‰ã‚’ç„¡è¦–
                crawl(full_url.split('#')[0], base_domain)

    except requests.RequestException as e:
        print(f"âš ï¸  ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {url} ({e})")
    except Exception as e:
        print(f"ğŸ’¥ ä¸æ˜ãªã‚¨ãƒ©ãƒ¼: {url} ({e})")
    
    # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚å°‘ã—å¾…ã¤
    time.sleep(0.5)


def main():
    """
    ãƒ¡ã‚¤ãƒ³å‡¦ç†
    """
    try:
        # domains.txtã‹ã‚‰ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆURLã‚’å–å¾—
        with open(INPUT_FILE, "r") as f:
            start_urls = [line.strip() for line in f if line.strip()]
        
        if not start_urls:
            print(f"ã‚¨ãƒ©ãƒ¼: {INPUT_FILE} ãŒç©ºã§ã™ã€‚ã‚¯ãƒ­ãƒ¼ãƒ«å¯¾è±¡ã®URLã‚’1ã¤ä»¥ä¸Šè¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ä»Šå›ã¯æœ€åˆã®1ã¤ã®URLã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
        start_url = start_urls[0]
        if not start_url.startswith('http' ):
            start_url = 'http://' + start_url
        
        base_domain = urlparse(start_url ).netloc
        print(f"--- ã‚¯ãƒ­ãƒ¼ãƒ«é–‹å§‹ ---")
        print(f"å¯¾è±¡ã‚µã‚¤ãƒˆ: {start_url}")
        print(f"ãƒ™ãƒ¼ã‚¹ãƒ‰ãƒ¡ã‚¤ãƒ³: {base_domain}")
        print(f"--------------------")

        # ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’é–‹å§‹
        crawl(start_url, base_domain)

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã™
        if found_cojp_domains:
            print(f"\n--- çµæœ ---")
            print(f"{len(found_cojp_domains)}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªco.jpãƒ‰ãƒ¡ã‚¤ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
            sorted_domains = sorted(list(found_cojp_domains))
            with open(OUTPUT_FILE, "w") as f:
                for domain in sorted_domains:
                    f.write(f"{domain}\n")
            print(f"çµæœã‚’ {OUTPUT_FILE} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        else:
            print("\nco.jpãƒ‰ãƒ¡ã‚¤ãƒ³ã¸ã®ãƒªãƒ³ã‚¯ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: {INPUT_FILE} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        print(f"è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()

